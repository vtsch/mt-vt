{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different LSTM and autoencoder approaches for encoding and k-means for clustering (MIT-BIH ECG data)\n",
    "\n",
    "Inspiration from:\n",
    "* https://github.com/navneetkr123/Clustering-using-deep-learning-LSTM-Autoencoder-Kmeans-/blob/master/switchon_new.ipynb\n",
    "\n",
    "* https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt('data/mitbih_train.csv', delimiter=\",\",dtype=float)\n",
    "test = np.loadtxt('data/mitbih_test.csv',delimiter=\",\",dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train)\n",
    "np.random.shuffle(test)\n",
    "\n",
    "print(\"original size train: \", train.shape)\n",
    "print(\"original size test: \", test.shape)\n",
    "\n",
    "#reduce nr. of samples\n",
    "train_small = train[:-77554]\n",
    "test_small = test[:-19844]\n",
    "\n",
    "print(\"small size train: \", train_small.shape)\n",
    "print(\"small size test: \", test_small.shape)\n",
    "\n",
    "#split to X and y\n",
    "X_train = train_small[:, 0:-1]\n",
    "y_train = train_small[:, -1]\n",
    "\n",
    "X_test = test_small[:, 0:-1]\n",
    "y_test = test_small[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create irregular TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of zeros in each row in original data (already irregular)\n",
    "n_zeros = np.count_nonzero(X_train==0, axis=1)\n",
    "print(n_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN DATA\n",
    "# random boolean mask for which values will be changed\n",
    "replace_rate = 0.3\n",
    "mask = np.random.choice([0, 1], size=X_train.shape, p=((1-replace_rate),replace_rate)).astype(np.bool)\n",
    "\n",
    "# random matrix the same shape\n",
    "r = np.zeros(shape=X_train.shape)\n",
    "#r = np.full(shape=X_train.shape, fill_value=-1, dtype=np.float32)\n",
    "\n",
    "# use  mask to replace values in input array\n",
    "X_train[mask] = r[mask]\n",
    "\n",
    "\n",
    "# TEST DATA\n",
    "mask_test = np.random.choice([0, 1], size=X_test.shape, p=((1-replace_rate),replace_rate)).astype(np.bool)\n",
    "r_test = np.zeros(shape=X_test.shape)\n",
    "X_test[mask_test] = r_test[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_zeros = np.count_nonzero(X_train==0, axis=1)\n",
    "for i in n_zeros:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(X_train)\n",
    "test = pd.DataFrame(X_test)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.values\n",
    "test = test.values\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKlearn K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnkmeans(encoded_data):\n",
    "    kmeans = KMeans(n_clusters=5).fit(encoded_data)\n",
    "    labels = kmeans.predict(encoded_data)\n",
    "\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    return centroids, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTW K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTWDistance(s1, s2,w):\n",
    "    DTW={}\n",
    "    \n",
    "    w = max(w, abs(len(s1)-len(s2)))\n",
    "    \n",
    "    for i in range(-1,len(s1)):\n",
    "        for j in range(-1,len(s2)):\n",
    "            DTW[(i, j)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "  \n",
    "    for i in range(len(s1)):\n",
    "        for j in range(max(0, i-w), min(len(s2), i+w)):\n",
    "            dist= (s1[i]-s2[j])**2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\t\t\n",
    "    return np.sqrt(DTW[len(s1)-1, len(s2)-1])\n",
    "\n",
    "def k_means_dtw(data,num_clust,num_iter,w=5):\n",
    "    centroids=random.sample(list(data),num_clust)\n",
    "    counter=0\n",
    "    for n in range(num_iter):\n",
    "        counter+=1\n",
    "        print(counter)\n",
    "        assignments={}\n",
    "        labels = []\n",
    "\n",
    "        #assign data points to clusters\n",
    "        for ind,i in enumerate(data):\n",
    "            min_dist=float('inf')\n",
    "            closest_clust=None\n",
    "            for c_ind,j in enumerate(centroids):\n",
    "                cur_dist=DTWDistance(i,j,w)\n",
    "                if cur_dist<min_dist:\n",
    "                    min_dist=cur_dist\n",
    "                    closest_clust=c_ind\n",
    "            if closest_clust in assignments:\n",
    "                assignments[closest_clust].append(ind)\n",
    "            else:\n",
    "                assignments[closest_clust]=[]\n",
    "            labels.append(closest_clust)\n",
    "    \n",
    "        #recalculate centroids of clusters\n",
    "        for key in assignments:\n",
    "            clust_sum=0\n",
    "            for k in assignments[key]:\n",
    "                clust_sum=clust_sum+data[k]\n",
    "            centroids[key]=[m/len(assignments[key]) for m in clust_sum]\n",
    "    \n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMAP\n",
    "\n",
    " Uniform Manifold Approximation and Projection (UMAP) -  projects the high-dimensional data points into 2D/3D by inducing the projected data to have a similar distribution as the original data points by minimizing something called the KL divergence.\n",
    " \n",
    "there are still valid reasons to use UMAP as a preprocessing step for clustering. As with any clustering approach one will want to do some exploration and evaluation of the clusters that come out to try to validate them if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umapt(data):\n",
    "    umap_2d = umap.UMAP(n_components=2, init='random', random_state=42)\n",
    "    #umap_3d = UMAP(n_components=3, init='random', random_state=0)\n",
    "\n",
    "    proj_2d = umap_2d.fit_transform(data)\n",
    "\n",
    "    return proj_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clustering on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, kmeans_labels = sklearnkmeans(test)\n",
    "\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"kmeans cluster centers original data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, dtwkmeans_labels = k_means_dtw(X_test,num_clust=5,num_iter=10,w=5)\n",
    "\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"dtw kmeans cluster centers original data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = umapt(X_test)\n",
    "plt.title(\"umap on original data with original labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=y_test, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on original data with kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=kmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on original data with dtw kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=dtwkmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to fit in lstm\n",
    "train_lstm = np.reshape(train, train.shape + (1,))\n",
    "test_lstm = np.reshape(test, test.shape + (1,))\n",
    "\n",
    "train_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(30, activation='relu', input_shape=(187,1)))\n",
    "model.add(RepeatVector(187))\n",
    "model.add(LSTM(30, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "history_lstm_seq = model.fit(train_lstm, train_lstm, epochs=200,\n",
    "          batch_size=16,\n",
    "          shuffle=True,\n",
    "          steps_per_epoch=50,\n",
    "          validation_steps=20,\n",
    "          validation_data=(test_lstm, test_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_lstm_seq.history['loss'], label='train')\n",
    "plt.plot(history_lstm_seq.history['val_loss'], label='test')\n",
    "plt.title(\"loss LSTM seq\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lstm_seq = model.predict(test_lstm)\n",
    "predicted_lstm_seq = np.reshape(predicted_lstm_seq, (2048, 187))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_lstm_seq[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, kmeans_labels = sklearnkmeans(predicted_lstm_seq)\n",
    "\n",
    "#plot centroids\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"kmean cluster centers lstm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, labels_dtwkmeans=k_means_dtw(predicted_lstm_seq,num_clust=5,num_iter=10,w=5)\n",
    "\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"dtw kmeans cluster centers lstm embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = umapt(predicted_lstm_seq)\n",
    "plt.title(\"umap on lstm embeddings with original labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=y_test, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on lstm embeddings with kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=kmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on lstm embeddings with dtw kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=dtwkmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Training of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of encoded representation\n",
    "encoding_dim = 15\n",
    "#input sequence\n",
    "input = Input(shape=(187,))\n",
    "# encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input)\n",
    "# lossy reconstruction of the input\n",
    "decoded = Dense(187, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder_ac = Model(input, encoded)\n",
    "# This is our encoded input\n",
    "encoded_input_ac = Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer_ac = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder_ac = Model(encoded_input_ac, decoder_layer_ac(encoded_input_ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "history_ac  = autoencoder.fit(train, train,\n",
    "                epochs=1000,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                validation_data=(test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_ac.history['loss'], label='train')\n",
    "plt.plot(history_ac.history['val_loss'], label='test')\n",
    "plt.title(\"loss simple autoencoder\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_ac = encoder_ac.predict(test)\n",
    "decoded_data_ac = decoder_ac.predict(encoded_data_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, kmeans_labels = sklearnkmeans(encoded_data_ac)\n",
    "\n",
    "#plot centroids\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"kmeans cluster centers simple autoencoder embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, dtwkmeans_labels =k_means_dtw(encoded_data_ac,num_clust=5,num_iter=10,w=5)\n",
    "\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"dtw kmeans cluster centers simple autoencoder embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = umapt(encoded_data_ac)\n",
    "print(umap_2d)\n",
    "plt.title(\"umap on simple ac embeddings with original labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=y_test, s=0.1, cmap='Spectral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on simple ac embeddings with kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=kmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on simple ac embeddings with dtw kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=dtwkmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Training of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(187,))\n",
    "\n",
    "encoded = Dense(128, activation='relu')(input)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "encoded = Dense(16, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(187, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_deep = Model(input, decoded)\n",
    "\n",
    "# This model maps an input to its encoded representation\n",
    "encoder_ac_deep = Model(input, encoded)\n",
    "encoded_input_ac_deep = Input(shape=(187,))\n",
    "#decoder_layer_ac_deep = autoencoder_deep.layers[-1]\n",
    "#decoder_ac_deep = Model(encoded_input_ac_deep, decoder_layer_ac_deep(encoded_input_ac_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_deep.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "history_ac_deep = autoencoder_deep.fit(train, train,\n",
    "                epochs=200,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                validation_data=(test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_ac_deep.history['loss'], label='train')\n",
    "plt.plot(history_ac_deep.history['val_loss'], label='test')\n",
    "plt.title(\"loss deep autoencoder\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_ac_deep = encoder_ac_deep.predict(test)\n",
    "#decoded_data_ac_deep = decoder_ac.predict(encoded_data_ac_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, kmeans_labels = sklearnkmeans(encoded_data_ac_deep)\n",
    "\n",
    "#plot centroids\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"kmean cluster centers deep autoencoder embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, dtwkmeans_labels = k_means_dtw(encoded_data_ac_deep,num_clust=5,num_iter=10,w=5)\n",
    "\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"dtw kmeans cluster centers deep autoencoder embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = umapt(encoded_data_ac_deep)\n",
    "plt.title(\"umap on deep ac embeddings with original labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=y_test, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on deep ac embeddings with kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=kmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on deep ac embeddings with dtw kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=dtwkmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Training of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 187\n",
    "input_dim = 1\n",
    "latent_dim = 10\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "encoded = LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "\n",
    "encoder_ac_lstm = Model(inputs, encoded)\n",
    "encoded_ac_input = Input(shape=(encoding_dim,1))\n",
    "#decoder_layer = sequence_autoencoder.layers[-1]\n",
    "#decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "history_ac_lstm = sequence_autoencoder.fit(train_lstm, train_lstm,\n",
    "                epochs=50,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_lstm, test_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_ac_lstm.history['loss'], label='train')\n",
    "plt.plot(history_ac_lstm.history['val_loss'], label='test')\n",
    "plt.title(\"loss lstm autoencoder\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_ac_lstm = encoder_ac_lstm.predict(test_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, kmeans_labels = sklearnkmeans(encoded_data_ac_lstm)\n",
    "\n",
    "#plot centroids\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"kmean cluster centers lstm autoencoder embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, dtwkmeans_labels = k_means_dtw(encoded_data_ac_lstm,num_clust=5,num_iter=10,w=5)\n",
    "\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.title(\"dtw kmeans cluster centers lstm autoencoder embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = umapt(encoded_data_ac_lstm)\n",
    "plt.title(\"umap on lstm ac embeddings with original labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=y_test, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on lstm ac embeddings with kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=kmeans_labels, s=0.1, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"umap on simple ac embeddings with dtw kmeans labels\")\n",
    "plt.scatter(umap_2d[:, 0], umap_2d[:, 1], c=dtwkmeans_labels, s=0.1, cmap='Spectral')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
